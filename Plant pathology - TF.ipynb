{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T14:32:00.520932Z",
     "start_time": "2020-04-19T14:31:55.670329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\distributions\\distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\distributions\\bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-35574ad673d6>\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1823, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 45, in <module>\n",
      "    from . _api.v2 import compat\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 23, in <module>\n",
      "    from . import v1\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 40, in <module>\n",
      "    from . import experimental\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\experimental\\__init__.py\", line 11, in <module>\n",
      "    from tensorflow.python.ops.control_flow_v2_toggles import output_all_intermediates\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_v2_toggles.py\", line 24, in <module>\n",
      "    from tensorflow.python.ops import control_flow_util_v2\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_util_v2.py\", line 28, in <module>\n",
      "    from tensorflow.python.keras.engine import base_layer_utils\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\__init__.py\", line 27, in <module>\n",
      "    from tensorflow.python.keras import applications\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import engine\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\__init__.py\", line 23, in <module>\n",
      "    from tensorflow.python.keras.engine.base_layer import Layer\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 56, in <module>\n",
      "    from tensorflow.python.keras.saving.saved_model import layer_serialization\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\__init__.py\", line 20, in <module>\n",
      "    from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.utils import conv_utils\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\__init__.py\", line 38, in <module>\n",
      "    from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\multi_gpu_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine.training import Model\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 42, in <module>\n",
      "    from tensorflow.python.keras import metrics as metrics_module\n",
      "  File \"C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\", line 34, in <module>\n",
      "    from tensorflow.python.keras.engine.base_layer import Layer\n",
      "ImportError: cannot import name 'Layer' from 'tensorflow.python.keras.engine.base_layer' (C:\\Users\\jvine\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet input image shape is (244, 244, 3)\n",
    "inputs = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "\n",
    "# Output is dependent on your situation (10 for CIFAR-10)\n",
    "outputs = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# VGG19 returns the last layer (softmax)\n",
    "# model to give the name\n",
    "logits = nets.VGG19(inputs, is_training=True, classes=10)\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "# loss function applied to the last layer\n",
    "# train on the loss (Adam Optimizer is used)\n",
    "loss = tf.losses.softmax_cross_entropy(outputs, logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss)\n",
    "\n",
    "# for measuring accuracy after forward passing\n",
    "correct_pred = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove previous weights, bias and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:46:38.992933Z",
     "start_time": "2020-01-30T12:46:38.308121Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c193d79f7d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a NN using TF to solve the CIFAR-10 Dataset using 2 layer fully connected layers and report your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:46:44.378989Z",
     "start_time": "2020-01-30T12:46:44.359066Z"
    }
   },
   "outputs": [],
   "source": [
    "ALPHA = 1e-2\n",
    "EPOCHS = 200\n",
    "HL_1_NEURONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:46:44.791107Z",
     "start_time": "2020-01-30T12:46:44.776300Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1529b341d5a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_X_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, len(std_X_train[0])])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T12:02:21.563166Z",
     "start_time": "2020-01-21T12:02:21.274644Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([len(std_X_train[0]), HL_1_NEURONS], stddev=1), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([HL_1_NEURONS]), name='b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T12:02:21.922845Z",
     "start_time": "2020-01-21T12:02:21.860350Z"
    }
   },
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([HL_1_NEURONS, 10], stddev=1), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation with ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T12:49:34.379775Z",
     "start_time": "2020-01-21T12:49:34.361788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute HL\n",
    "hl = tf.nn.relu(tf.add(tf.matmul(X, W1), b1))\n",
    "# Compute prediction\n",
    "y_pred = tf.nn.softmax(tf.add(tf.matmul(hl, W2), b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T12:02:28.974472Z",
     "start_time": "2020-01-21T12:02:27.406391Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.add(tf.matmul(hl, W2), b2), labels=y_train_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.GradientDescentOptimizer(ALPHA)\n",
    "updates = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T13:27:19.723870Z",
     "start_time": "2020-01-19T13:24:33.593162Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_list = []\n",
    "batches = [std_X_1, std_X_2, std_X_3, std_X_4, std_X_5]\n",
    "with tf.Session() as sess:\n",
    "    for i in range\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train the model\n",
    "    values = {X: std_X_train,\n",
    "              y: y_train_one_hot}\n",
    "    start = time.time()\n",
    "    for e in range(EPOCHS):\n",
    "        cost_val, _ = sess.run([cost, updates], feed_dict=values)\n",
    "        cost_list.append(cost_val)\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    pred = sess.run([y_pred], feed_dict={X: std_X_test, y: y_test_one_hot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T13:27:20.946347Z",
     "start_time": "2020-01-19T13:27:20.786329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAFQCAYAAABUJbLpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3gc9aH18e/salddsixb1R2DKXEB0zE4kATTawiQxFQDpsaUkHLDe2khwAUukIt9Y1ooCRDSaE6IL92OqQE7WO64q1pdlrbP+8fKQrKklbR1dnU+z6NH1szs7NFI3qPftDUOOfokExERkW5siQ4gIiLWo3IQEZFeVA4iItKLykFERHpROYiISC9p8XyyrOwcvF5PPJ9SRET64XA4ad/d1ue8uJVDVnYO35t7dbyeTkREBuEPzy3qsyDiVg57Rgx/eG5RmKMHg5y8EbS1NAFWvTRDGaPD6hmtng+UMVqsnjH8fA6Hk+/Nvbrf1+O47laCYEl4PeGVg8/r7XysFX9IoIzRYvWMVs8HyhgtVs8Yu3w6IC0iIr2oHEREpBeVg4iI9KJyEBGRXlQOIiLSi8pBRER6UTmIiEgvKgcREelF5SAiIr0kVTlY8fpEEZFUlDTlYJQcjnvcWYmOISIyLAx4b6VZxxzFFfMu7TEtIyODF158mQ8/+pj5V81j4oQJ1NTWsHjxU2zc9FVskgZ8mDZnbNYtIiI9DFgOy5avYNnyFV1fH3fsMZx91hm8+Y//4z9v+xkrPvyYu+6+l2NnHc2NC67nuhtuwjRjsAPI7wGVg4hIXAxpt9KIEflccvEPWbhoMSMLCiguLua115fg9/t5970P6HB1MH3a1JgENf1uTLsjJusWEZGehnTL7vPPO5ePPv6UDRs3cdihM6mprSUQCHTNr66qoby8jC9WrgqxFqPzY4gCHrDtKYcwHh93yhgdVs9o9XygjNFi9YxDzRd6+UGXQ35+PkcffRS33PozANIz0vHs9b4Mbo+H9PTQu35y8kbg83oH+7Rd/BkZuG1OcvILLP8jys0vSHSEASlj5KyeD5QxWqyeMZx8aY7Qe2IGXQ7HHH0kFWvWUFe3CwCP24PT2bMI0p1OXC53yPW0tTSF92Y/bht2oK1td/D4g0Xl5hfQ2tyY6BghKWPkrJ4PlDFarJ4x3HwOZ+g/5AddDjNnHsx7733Q9fXOykqKi0ZjGEbXAejS0hKWvvX2AGsyCeuKBX9n6djSv/635XQf01j1qgxljJzV84EyRovVM0aSL/TygzogbRgG+0yayPoNG7um7dxZSV3dLs45+wzsdjuzj5tFVnYWFRVrhxhwkPaMFuw6Y0lEJNYGNXLIyckhMzOTxsamHtMffOhRrrryMk479RRqamt54IGH8YZxPGFQAioHEZF4GVQ5tLa2cv6FF/WaXlNby5133xv1UP3ye8CeHr/nExEZppLm9hkARsCrkYOISBwkVTkQ8GDoKmkRkZhLqnLQyEFEJD6SqhwI6JiDiEg8JFU5aOQgIhIfSVUOwZGDykFEJNaSqhyCIwftVhIRibWkKgeNHERE4iOpysEIeHUqq4hIHCRVOaDdSiIicZFU5WBot5KISFwkVTmgU1lFROIiqcrBCHhAxxxERGIuqcoBv445iIjEQ1KVgxHwYNgdWP+NvkVEkltSlQOBzjcS0nEHEZGYSqpyMLreDU67lkREYimpykEjBxGR+EiucjB9mGZAIwcRkRhLqnIwIPg+0jqdVUQkppKqHADwu7VbSUQkxpKwHDwY2q0kIhJTSVgOGjmIiMRakpZDRqJTiIiktOQshzTtVhIRiaWkKwfT79aprCIiMZZ05YDKQUQk5pKvHHxuDB1zEBGJqeQrB79LIwcRkRhLwnLQbiURkVhLG8xCo0eNYt68S5iy3760trXx0h/+xLJl/6SkpJj5V81j4oQJ1NTWsHjxU2zc9FVMA5t+N4bOVhIRialBjRx+fMsCvvpqC5fNu5qHH3mMKy6/hNGjR7Hghmv5/POVXDZvPkuWvMmNC67HMGL8Rjw+XecgIhJrA5bDfvtOJjMrkz+8/CcCgQCbNn3Ff9x2BxkZGRQXF/Pa60vw+/28+94HdLg6mD5tamwTa7eSiEjMDbhbacKE8ezYsZNLLv4hRx55OK0trfz+xT9gt9mpqa0lEAh0LVtdVUN5eRlfrFwVu8R+d3B0YnPCnjf/ERGRqBqwHHJyspk+bSrPPvd7rrl2Ad846EBuuvF6Xnn1DTyeni/Obo+H9PSB7ntkENF7QPtdwc9pGeDxhr+emEuG97lWxshZPR8oY7RYPeNQ84VefsBy8Hp97NpVz9/fXArAylX/Zs3adRgGOJ09iyDd6cTlcodcX07eCHze8F/Uc7Kz6ACy80dj8wzqeHrc5eYXJDrCgJQxclbPB8oYLVbPGE6+NIcj9PyBVlBVVU1WVlaPaTabjfb2DoqLRmMYBqZpAlBaWsLSt94Oub62lia8nvB2B+XmF9DWVIct4Gd3hxvaGsNaTyzl5hfQ2my9XN0pY+Ssng+UMVqsnjHcfA5n6L08Ax6QXvXvL/H6vHzvvHMxDIMZ06cxZb99+eTTz6ir28U5Z5+B3W5n9nGzyMrOoqJi7QBrNMP86KbroHS464rVRzS+T2W0fkar51PG4ZMx0nz9G3Dk4PF4uPOuX3H5pRfz5OMLaW5u4dH/WcSuXfU8+NCjXHXlZZx26inU1NbywAMP441gl9GgdV7rEPpbExGRcA1qp31VVTV333Nfr+k1tbXcefe9UQ81IN1CQ0QkppLv9hmgN/wREYmx5CwHny6EExGJpaQsB73hj4hIbCVlOeB36a1CRURiKEnLwaM3/BERiaEkLQedrSQiEkvJWQ46IC0iElPJWQ46IC0iElNJWQ6m3x28K6uIiMREUpaDjjmIiMRWcpaDz41hSwPDnugkIiIpKTnLofsb/oiISNQlZzn4OoKf7ZmJzSEikqKSsxwCXkwzoJGDiEiMJGc5QHD0oHIQEYmJJC4Hl26hISISI8lbDn6XRg4iIjGSvOXgc0GaDkiLiMRC0paD6Xfp3eBERGIkactBB6RFRGInictBB6RFRGIlectBB6RFRGImecvBp3IQEYmV5C4H7VYSEYmJpC0H069TWUVEYiVpywFfh97TQUQkRpK4HFwYhqFdSyIiMZC85aD3dBARiZnkLQdfZzlo5CAiEnXJWw6YmD63DkqLiMRAEpcD4O+ANB2UFhGJtrTBLHTaqSdz4QXn4fP5uqYtuOlWCkeOZN68SyktKWHrtm0sXLSY6uqamIXtxefCsGdixu8ZRUSGhUGVw4QJ43ju+Rf4+5tLu6Y5HA7u+eUdPP/8i3z40cecdeZpXDP/Cv7f7XfHLGwvuoWGiEhMDGq30oTx49m6dVuPaQcdeAAd7R0s/+cK/H4/f/7Lq4wdO4bysrKYBO2TbqEhIhITA44cHA4HpaUlnH76qdy44Hqampp44aWXKS0pYWdlZddypmlSW1tHeXlZj+m9GZ0fkQg+3vS5wJ4ZhfXFghUz7U0ZI2f1fKCM0WL1jEPNF3r5AcshLy+P9Rs28uabS3lwdQXTp01lwQ3X8sqrb+DxeHss6/Z4cKY7Q64vJ28EPq835DKh5OYXdP3bYwczPY/0btOsINdiefqijJGzej5QxmixesZw8qU5HKHnD7SC+vp67rjznq6v//X5F6xevQa3243T2XPl6U4nLpcr5PraWprwejwDPW2fcvMLaG1u7PrayG7EyMvF021aou2d0YqUMXJWzwfKGC1WzxhuPocz9B/yA5bD+HFjmT59Kq++tuTrBznS8Hq9lJaWdE0zDIOioiIqK6sGWKPZ+TFU3YdAnY/37QZHVpjri4U+MlqOMkbO6vlAGaPF6hkjyRd6+QEPSLd3dHDuOWczc+bBGIbBkUccxr6TJ/PxJ5+Sm5PD7ONmYbfbOefsM6iurh5EOUSP6W2HtKy4PZ+IyHAx4Mihrm4Xj/7PQi684DxuuO4aqqur+a8H/pumpmbuvf8hrrj8Ei69ZC5btm7j4Ucei0PkbnwqBxGRWBjUdQ6fffY5n332ea/pmzdv4ee/uD3amQbP145hd4AtDQK+gZcXEZFBSe7bZ3jbg581ehARiarkLgdfR/CzykFEJKqSuxwwMX0dnWcsiYhItCR5OQDedgyNHEREoir5y8HXrpGDiEiUJX856FoHEZGoS/pyMH3tejc4EZEoS/pyQAekRUSiLvnLwduOkZad6BQiIikl+cvB1w4O7VYSEYmmpC8HU/dXEhGJuqQvB52tJCISfclfDr52DJsd7OmJTiIikjKSvxx08z0RkahL/nLwuzDNgE5nFRGJouQvB9BxBxGRKEuRcmjDcOhaBxGRaEmRctgNjpxEpxARSRkpUQ6mtw2cKgcRkWhJiXII7lZSOYiIREtqlIOnTbuVRESiKDXKwbsbdEBaRCRqUqIcdMxBRCS6UqIc8LZh2NPB5kh0EhGRlJAa5eBpC37WcQcRkahIjXLwuzADfpWDiEiUpEY5AHjbdFBaRCRKUqocDB2UFhGJitQpB13rICISNSlTDqZ2K4mIRM2gy6G8vIznnnmC4uIiACbvM4l7f3UXzzz9OHfecRslJcUxCzko3t26hYaISJQMqhxsNhtXz78Cp9MJgMPh4Oabf8Rrry3hsnnzWblyFdfMvyKmQQekC+FERKJmUOVw1pmns27d+q6vDzrwADraO1j+zxX4/X7+/JdXGTt2DOVlZTELOhBTxxxERKJmwHIYP24sRx91BC++9MeuaWVlpeysrOz62jRNamvrKC8fTDkYYX4MsA5PCzhzwbBH8ByRfkTj+1RG62e0ej5lHD4ZI83Xv7RQM+12O1fPv4LHn3gar9fbNT0jIx2Px9tjWbfHgzPdGfLJAHLyRuDzegdcrj+5+QV9Tjft0GHYyC4ci83bEvb6o6G/jFaijJGzej5QxmixesZw8qU5Qt9uKGQ5fPfcs1hdsZZ16zf0mO52e3A6e6443enE5XINGKitpQmvxzPgcn3JzS+gtbmx3/k2n5vdHhu09L9MrA2U0QqUMXJWzwfKGC1WzxhuPocz9B/zIcvhiMMPo6BgBMd/89iuaffecxdPPPlbSktLuqYZhkFRURGVlVWDiGR2fgxV9yFQP493N2JkjMBsCWf90TCIjAmnjJGzej5QxmixesZI8oVePmQ53HTLT3t8/dILz/LTn99GQ0MjF829kNnHzWLZ8hWcdeZpVFdXD7IcYsjdBOkjEptBRCQFhHURnNfr5d77H2LOid/myccXMnXqN3j4kceinW3ITFcjZFh736CISDIIOXLY2/kXXtT1782bt/DzX9we7TyRcTdh5I2z5OBPRCSZpMztMwBMdyOka+QgIhKplCoHXI0YjiywD3xKrYiI9C+1ysHdFPys0YOISERSqxxMP6anRWcsiYhEKLXKAcDVhKGRg4hIRFKuHEy3TmcVEYlUypUDrgaMjJGJTiEiktRSshxQOYiIRCTlysF0NUB6PsFbd4uISDhSrhxwNWAYNp2xJCISgdQrB78b07sbMgoTnUREJGmlXjmADkqLiEQoJcvBdDVApspBRCRcKVkOuBow0lUOIiLhStFyqNfIQUQkAilZDmZHAzh1OquISLhSshxwN2AYhm6jISISptQsB78H09Oq01lFRMKUmuUA0LELI3N0olOIiCSllC0Hs2MXZGrkICISjpQth+DIYVSiU4iIJKWULQfTVQ8ZKgcRkXCkbDnQsQsjLR0cOYlOIiKSdFK3HDwtmH4PaNeSiMiQpW45gI47iIiEKaXLIXjcQWcsiYgMVUqXg651EBEJT0qXg9lRB1narSQiMlQpXQ6012I488CekegkIiJJJbXLwdWIGfBCVnGik4iIJJW0wSw065ij+O65Z1NQMIKdOyt55tnfsW79BibvM4l58y6ltKSErdu2sXDRYqqra2KdeQhMaK/DyCrCbN2a6DAiIkljwJFDaWkJl192CY/8eiEXX3olb739LjcuuB6Hw8HNN/+I115bwmXz5rNy5SqumX9FPDIPidlRC1lFiY4hIpJUBiyHqqpq5l9zA5s3byEtLY3s7Gza2to46MAD6GjvYPk/V+D3+/nzX15l7NgxlJeVxSP34LXXYqgcRESGZFDHHNxuNxMmjOe5Z57ge+edw7PP/Z6yslJ2VlZ2LWOaJrW1dZSXW6sczPZayFQ5iIgMxaCOOQBs376DH150OcfOOpobF1zP628swePx9ljG7fHgTHcOsCaj8yMSQ3h8e13wHkvpI8DdHOHzDkWk32M8KGPkrJ4PlDFarJ5xqPlCLz/ocvD7/QC8+94HnHrKSXi9XpxOR49l0p1OXC5XyPXk5I3A5/WGXCaU3PyhvfWnCXT4OsgcNYm0ti1hP+9QDDVjIihj5KyeD5QxWqyeMZx8aQ5H6PkDreDgg6dz4ne+xX33P/T1g9LSqKys5rjjZnVNMwyDoqIiKiurQq6vraUJr8cz0NP2KTe/gNbmxiE/zra7Ghe5mGE8dqjCzRhPyhg5q+cDZYwWq2cMN5/DGXovz4DHHL76agtT9tuXIw4/DJvNxpwTv43dbmflqn+Tm5PD7ONmYbfbOefsM6iurh6wHIJ/y4fzEf46zNbtGLljInju2GeM34cypn4+ZRw+GSPN178By6G5uZkHH3qUc885kycfX8hhh83kV/c9gNfr5d77H2LOid/myccXMnXqN3j4kccGWl1CmK3bIHcM1t9nKCJiDYM65rC6Yg23/vQXvaZv3ryFn//i9mhnir7W7WBzQHYJ7B5oZCMiIql9+4w9Al7YXYWROy7RSUREksLwKAcIHnfIUzmIiAzG8CmHlq2gkYOIyKAMm3KgdRukZekOrSIigzB8ysHXAa3bMQqmJDqJiIjlDZ9yAMzGdRgF+yU6hoiI5Q2/csgpA2duoqOIiFjasCoHXA2YHXXatSQiMoDhVQ6A2bAeY+T+iY4hImJpw68c6ldD3gRwZCc6ioiIZQ27cqC9Glz1GIUHJTqJiIhlDb9yAMxdqzEKv5HoGCIiljU8y6H+y+AtvNNHJDqKiIglDctywNWA2bZTowcRkX4Mz3IAzF1fYoxSOYiI9GX4lkP9asgcDVlFiY4iImI5w7Yc8LZByxaMwqmJTiIiYjnDtxzovmtJbx8qItLd8C6HhtWQlgEj9k10FBERSxnW5YDfg1m3Elvp4YlOIiJiKcO7HACz+hPImxg8OC0iIoDKAVz10LQRo+SwRCcREbEMlQMQqP4YY9R0sGckOoqIiCWoHACaN4GnGaPo4EQnERGxBJVDJ7P6k85dSzqtVURE5dDJrFsJ9kzQe0yLiKgcugQ8mHWfYys5ItFJREQSTuXQTfC01vG635KIDHsqh+7cjdC0AUOjBxEZ5lQOewlUfYQxaqreY1pEhjWVw95aNkNHHUaxLooTkeErbTALHTrzEC644LsUjiykqrqaZ579HevWrWfGjGlcPPcHjBw5kjVr17Jw0WJaWlpjnTnmzMoVGBNPxqxcDgFvouOIiMTdgCOHoqLRXHvNlTz51DNcNm8+S5b8nVtvWcCoUYX86PpreOLJ3zLvymtoaGjk4rk/iEfmmDMbKsDvxig6JNFRREQSYsByGD1qFG+9/S5r1qzDNE2WLV9BwDT55uxjWbd+A6sr1uD1ennhxZc58sjDycxMgVtQmAHMyuUYZUeDMajBlYhIShnwlW91xRpWV6zp+nrfyfuQkZ5OdnY2lZVVXdNbW1txu92UFBezecvWEGs0iPwq5NhfxWzWrsQoOwaj+FDM6o/CWEMyXGmtjJGzej5Qxmixesah5gu9/JD+LC4uLuKmG6/nDy//mbLSEppbWnrMd3s8ONPTQ64jJ28EPm/4+/Fz8wvCfuxQ+Rr+hWfMLDJdX2GYvkE/Lp4Zw6WMkbN6PlDGaLF6xnDypTkcoecPdkWT95nEj398I0uXvsVrry/hkot/iNPp7LFMutOJy+UKuZ62lia8Hs9gn7aH3PwCWpsbw3psWFpWYCs4mN2ZkzGrVgzqIXHPGAZljJzV84EyRovVM4abz7HX6/feBlUOM2ZM40fXX8Nzz7/A2++8B0BlZRUHHzy9a5m8vFwyMjKorq4ZYG1m58dQdR8ChfP4MJh+zJ3vY4z7DmbNpxAYqNQSkHHIlDFyVs8HyhgtVs8YSb7Qyw94QHrUqEIW3HAti37zRFcxAHzy6WfsP2U/pk+bisPh4ILzz+Ozzz7H7XYPMaC1mXWrwO/SmwGJyLAy4Mjh1FNOIj09nWuvvpJrr76ya/p99z/Ew488xkVzv8/IkSNZu24dCxctjmnYxDAxd7yHMeEkzJpPwB/eLjERkWQyYDk88+zveObZ3/U7/+Yf/yyqgazI3PUlRvmxGCVHYO78INFxRERiTrfPGJTO0UPpUWAPfTaWiEgqUDkMkllfAZ4WjLJjEh1FRCTmVA6DZhLY9hZG6RHgzEt0GBGRmFI5DEXTBmjdjjH2hEQnERGJKZXDEAW2LsUY9Q3ILk10FBGRmFE5DFV7DWbdKmzjT0x0EhGRmFE5hMHc/g5kl0HBlERHERGJCZVDOLytmFUrsI37NhjahCKSevTKFiazcjnY0zGKZiY6iohI1KkcwhXwYu54B2PMbF0YJyIpR+UQAbP2i+CFcTq1VURSjMohIiaBzUswimdCTnmiw4iIRI3KIVJtOzBrPsM28VQdnBaRlKFXsygwt78NjmyMksMTHUVEJCpUDtHgd2NueRNjzGwCjtxEpxERiZjKIUrMhgpo2YqnZHaio4iIREzlEEWBLX8nkFUOIw9IdBQRkYioHKLJ3YSj7mNsE+bo2gcRSWoqhyhLa1gJ3naMsccnOoqISNhUDlFmECCw+Q2M4kODN+cTEUlCKodYaNsZvPZhn9PBsCc6jYjIkKkcYsTc/hbYHBjjvpXoKCIiQ6ZyiBW/h8DGv2AUHwb5+yQ6jYjIkKgcYqltJ+bOD7BNOl1nL4lIUlE5xJhZuQx87RjjvpPoKCIig6ZyiDUzQGDTqxijp2MUHpToNCIig6JyiIf2aswtf8OYdAZkFSc6jYjIgFQOcWLW/gtz1yps+50HNkei44iIhKRyiCNzy5sQ8GFMmJPoKCIiIakc4sn0Edj4Z4xR0zBGT090GhGRfqUNZeEjjziMk046kdvv+CUAJSXFzL9qHhMnTKCmtobFi59i46avYhI0ZbTXYm56FWOfM8HvDd7qW0TEYgY1cjAMg9NOPYnrrp2PgdE1fcEN1/L55yu5bN58lix5kxsXXI9hGCHWJABm/ZeYm5dgTD47eJGciIjFDKocvn/h+Rw68xBeefX1rmnlZWUUFxfz2utL8Pv9vPveB3S4Opg+bWrMwqYSs+5zAhv+iDHuWxgTT9H7T4uIpQxqt9IbS/5GU1Mzs4+bBZ2n6peVlVJTW0sgEOharrqqhvLyMr5YuSrE2ozOj0gkw+hkEBkb1xNY/VtsU87H2H8UgQ1/BF9H7KN1SZHtmFBWzwfKGC1WzzjUfKGXH1Q5NDU195qWnpGOx+PpMc3t8ZCe7gy5rpy8Efi83sE8bZ9y8wvCfmy8DC2jB3PrH3GPOQXbtHmkb38dm6cpZtn2SL3tGH9WzwfKGC1WzxhOvjRH6FPqh3RAujuP24PT2bMI0p1OXC53yMe1tTTh3atUBis3v4DW5sawHhsv4WVshManMSadRsf48zC3/A1z179jkg9SeTvGj9XzgTJGi9UzhpvP4Qz9h3zY5bCzspLiotEYhoFpmgCUlpaw9K23B3ik2fkxVN2HQOE8Ph4iyGj6MDf9FYoOwZh4KuSOwdz8t6GvZ0Apvh3jwur5QBmjxeoZI8kXevmwj4Lu3FlJXd0uzjn7DOx2O7OPm0VWdhYVFWvDXaUQvJI6sPpJjBH7YZtyPtgzEh1JRIahiE6RefChRznowAN4YvFCTj55Dg888DDeCI4nSKf2WgKrnwRHNrbpV8OIfROdSESGmSHtVnrv/WW89/6yrq9ramu58+57ox5KAE8rgS+fwig7Btt+38Pc9W/Mrf8AvyvRyURkGNDJ9ZZmYlYuI/Dl4xjZxdgOvh6j5Aisf0qdiCQ7lUMyaK8l8O8nMLe8GRxJHDgXnHmJTiUiKUzlkDRMzF2rCPz7NxDwYZtxXfDK6vT8RAcTkRQU9qmskiDe3QTW/h7yJmIrPxZj+nWY9asx6z6Hlq2JTiciKULlkKxaNhNo2Qw5YzFKD8e2/w+gYxeBbf8HzbozrohERuWQ7Nq2Y27YjpmWiVE2C9uUC8DVgFn7BeauVeBrT3RCEUlCKodU4evA3LYUs+qfwTcTKj4EY9y3oGk9gdovoGkj1rzCU0SsSOWQary7MatWYFatgJwxGEUzsO17Dvg9wWMTLdswjZZEpxQRi1M5pLK2HZhtO4KnwBYehFGwb/Dmfo4sbO21mC1boXUrZss28LYlOq2IWIjKYTgIeDHrvsCs+wIwyB69D+22EZA7DmP8HGzOXMyOeszWbdCyFbN1K7h736ZdRIYPlcMwZPM0YDZvgppPg0ch0gsw8sZD3jiMMbOxZRRgups7Rxbbgp9d9YmOLSJxpHIQcDdi1jVC3RfBsnDmYeSOC5ZF6RHYJp2G6WmD1u2Yu6sw23ZC61YwAwOtWUSSlMpBevO0YNZ/CfVfBssiLStYFLnjMPInYZQfC5jQthNzdyVmWyW0VYJHu6JEUoXKQQbma4eGtZgNa4NlYdghbzxGTjlGdlnw1FlnLqanLXi8omUL5u5qaK+BgC/R6UUkDCoHGTrTD81fYTZ/9fWVE87c4KmzeRMwig7FyBodnN6xC7O9BtoqMdt2qDBEkoTKQaLD0woNazAb1nw9usgqwsgqhuwSjFHfwBj3bTBs4G4MlkZHHbTXdX3GVGmIWIXKQWLD9MPuKszdVVDXeW22LQ0yRmFkjoKs0RiZo6Fgf4yMguBjXA2dZVGLjw7wbgPXLo00RBJA5SDxE/BBezVmezXUd7uZh5EGmaMwsoogqxgjpxxvVhG28jkYhoHpboKOesz2Wuio7fy8CwJ6S1qRWFE5SOKZ3UoDMDHIzi+gtbUVMkZiZBZC5p6RxmSMjELA6Nw9VY/pqgdXPWZHPQ9wtOwAAA0wSURBVHTUg7c1sd+PSApQOYh1BXzQXhM8oE33kYY9ONLIHA2ZhZBRiJE3HiOjEMPuxPR1fH0so6MOs70uuMtKp9qKDJrKQZKP6e9RGtCtOJx5wQPhmaODxzVGTcXIHB0sjYAXXI3dRhl1mB27tItKpA8qB0ktnpbgRXxNG4FupeHICe6iyiiEzMJgeYw8ACOjAMOwYboag++D4WoIXjHe+TXuRh0Ql2FJ5SDDg7cNvG3Bmwuy9y6qzrLIKISMAozOM6gMZ25wWXcLuBs6Rxu7MN3N+J1Au0d3s5WUpXKQ4c30Q3vnGVB7Ju35h80BGQWQPhIjY2SwRAoPwkjPw+3IxT7RwAz4gwfA3U2Ynlbwe4IfAS8EPODv/GyawWs8MMAwgp8xg9MJBD+bga/nGQZg61zM7LZs5+ceyxlfJ++2jC8rGyOtvXN257J9rQv6WF/PZUwCgIHRfZm91mfu+T465xtd6wquzzQDPdeLDV92Lth3Bx+C0XsZk57593yvXevo43vY829zr23S9ZPta7vRc33Gnnk2fNk5YBvd82fV78/B6L3MILYvnduXENv36/V242okVlQOIv0JeKG9NlgenZOCnw1y8gtp6/CCMxfDmQcZI8CRC3ZHcJrNAXZnsGDszs4H9/Ef3LB1K4I+Xrz3vDp2X6bPFxd6vQB57WkYft9e64OeL0C23s/X/QW5cxmjz2x0W5+tWxn0na2vYvEaBraAv9uWNXp9H30Xwd5FS9/bLdT3anZbrvsyhhEs6s75XsPAZnZ/8e72c+hVePReZu9s3b+H7s/b6/vcO1vn70A35tY3wb2FWFA5iITBINB5fKO5zzdf7WtafHWeDtzcaIk0fVPGyBmQXxCTNdsGXkRERIYblYOIiPSichARkV5UDiIi0ovKQUREeon4bKXJ+0xi3rxLKS0pYeu2bSxctJjq6pqBHygiIpYV0cjB4XBw880/4rXXlnDZvPmsXLmKa+ZfEa1sIiKSIBGVw0EHHkBHewfL/7kCv9/Pn//yKmPHjqG8rCxa+UREJAEi2q1UVlbKzsrKrq9N06S2to7y8rIe03vqftVguCJ9fDwoY3RYPaPV84EyRovVMw41X+jlIyqHjIx0PJ6etzp2ezw40539PiYnbwQ+b/i3R86N0dWA0aSM0WH1jFbPB8oYLVbPGE6+NIcj9PxwwwC43R6czp5PkO504nK5+n1MW0sTXo8nrOfL7bqM3bqUMTqsntHq+UAZo8XqGcPN53D2/0c8RFgOOysrOf7447q+NgyDoqIiKiur+g/kcBDePUoM0hyOzm/Iivc4AWWMFqtntHo+UMZosXrG8PM5YjlyWL16Dbk5Ocw+bhbLlq/grDNPo7q6us9ycDiCLfW9uVdH8pQiIhJFDoezz705xiFHnxRRHU6cOIErLr+EsrJStmzdxqJFj1NTW9vnslnZOXi94e1SEhGR6HI4nLTv7vsNqyIuBxERST26fYaIiPSichARkV5UDiIi0ktSvE2oFW/ud+jMQ7jggu9SOLKQqupqnnn2d6xbt55LL5nLCcfPJhAIAOD3+7lsXmLO0Drt1JO58ILz8Pl8XdMW3HQrhSNHWmJ7zjrmKK6Yd2mPaRkZGbzw4stUVVVzw/VX98h+9z33s2HDxrjlO/KIwzjppBO5/Y5fAlBSUsz8q+YxccIEamprWLz4KTZu+mrAefHMOGXKflw89/uUlpbS0NDACy++zKef/Qvo//ehsbEprhmPOPywfn+2idiO3fPtP2U/fvbTW3rMdzqdvP3Oezz+xNNMmjSRX971n3i6nd3zv795khUffhSTbP29zsyYMY2L5/6AkSNHsmbtWhYuWkxLSytAyHlDYfkD0g6Hg0cfeYDnn3+RDz/6mLPOPI3p06by/26/O2GZiopGc9+v7uL+B/6btWvXc8zRR3LpJXO57oab+emtN/PKa6/zr399kbB8e1x37VVs3PgVf39zadc0K27PPY479hjOPusMfv6L2znj9FNwOp089/wLcc9hGAannjKHC84/j02bNvOfdwS3zb333MmKDz/m9Tf+xrGzjua8757DdTfchGmaIefFK2NGRga/fvRBnnrqWT786GMOPHB/brlpAT/92W3U1Nb2+fsQS/1tx/O/d26/P9t4bsf+8nV30IEHcP11V/Mft91BfX09Jxw/mxnTp/HQw7+Oep699fc685Of3cZ/3fdLHnjwEdZv2Mill8wl3enk14/9L/n5+Tz80H19zhsqy+9WsuLN/UaPGsVbb7/LmjXrME2TZctXEDBNystKGTduLFu3bk9Ytu4mjB/P1q3bekyz4vYEGDEin0su/iELFy2mo6OD8X1kj5fvX3g+h848hFdefb1rWnlZGcXFxbz2+hL8fj/vvvcBHa4Opk+bGnJePDOOGlXIF1+sYsWHH2GaJqtXr6GquppJkyYCff8+xFJfGYF+f7bx3o795dvD6XRyzdVX8ttnn6e+vr4z+zi2bovPNuzvdeabs49l3foNrK5Yg9fr5YUXX+bIIw8nMzODww+b2e+8obL8bqXwbu4XW6sr1rC6Yk3X1/tO3oeM9HRM0yQ93cnll17EvvvuQ3V1Lc8+9zs2bNwU94wOh4PS0hJOP/1UblxwPU1NTbzw0suUlpRYbnsCnH/euXz08add22rC+HGk2e18/8Lz6ejo4JVXX+fd9z6IS5Y3lvyNpqZmZh83Cw4KTisrK6WmtrZrdyFAdVUN5eVlOByOfud9sXJV3DLu2LGTxxb+pmuZ0aNGMXZMOdt37Oj39+Hzz1fGJF9/GaH/n22obRyL7dhfvj1OO/Ukqqqr+fDDj7tlH4/f7+OE479JIBDgrbff4a+v9F0ukervdSY7O7vHhcatra243W5KiospKyvtd97mLVuH9PyWL4dwbu4XT8XFRdx04/X84eU/A1BRsZY//eUVtmzZyuzZx/KTW2/mxpt/Qmvr0Pf5RSIvL4/1Gzby5ptLeXB1BdOnTWXBDdfyyqtvWG575ufnc/TRR3HLrT8DgsVWXVPDe+8v46OPP2HSxAn85Nab2LWrni9XV8Q8T1NTc69p6RnpPfYzQ3C7pac7Q86LZ8bucnNz+cmtN/HOu++zY8dOCgsL+/x9+Pl/3B6zPwr6yhjqZxvv7RhqGzocDk6acyIP/fejPaa3tLZQUbGWt95+l6Ki0dx6y400N7fwzrvvxyTjHt1fZ8pKS2huaekxP/h/OJ2M9PR+5w2V5cshnJv7xcvkfSbx4x/fyNKlb/Ha60sAuPue+7rmv/32u5w85zscsP8UPv7k07hmq6+v54477+n6+l+ff8Hq1Wtwu92W257HHH0kFWvWUFe3CwCv18udd/2qa/76DRtZtnwFhx56SFzKoS8etwfnXjcqC243d8h5iVBSUszPfnILFRVrePq3zwH9/z7MmDEtriPGUD/bioq1ltmOM6ZPo6W1hbXr1veY/uBDX5fFjh07+cfS/+PQQw+JaTns/TpzycU/7Gc7uYJF0M+8obL8MYedlZWUlpZ0fT2Ym/vFw4wZ0/iPn9/KSy/9kT/+6a8AHHjA/pxwwjd7LJfmcOBJwC1Dxo8byxmnn7JXljS8Xq/ltufMmQezYsXXZ3sUFhZy4QXn9VgmLS2YPVF2VlZSXDQaw/j6HvilpcFddKHmxdukSRO5647b+GDZcn7z+FNdB3JD/T7EU6ifrZW2496/kxA8k27uDy/s8eKbluaI6Tbs63WmsrKqx//hvLxcMjIyqK6uCTlvqCxfDt1v7me32znn7DP6vblfvIwaVciCG65l0W+e4O133uua7vf7mfuDC5m8zyRsNhunnDwHp9PB6tVrQqwtNto7Ojj3nLOZOfNgDMPgyCMOY9/Jk/n4k08ttT0Nw2CfSRNZ3+0U1ba2Nr51wvF859snYBgGBxwwhaOPOpJly1ckJCPAzp2V1NXt4pyzz8ButzP7uFlkZWdRUbE25Lx4yszM4Me3LOAvf32t64Vkj1C/D/EU6mdrle0IMHnypB6/kwAul4tDDp7Bueecic1mY9y4scyZ823e/2B5TDL09zrzyaefsf+U/Zg+bSoOh4MLzj+Pzz77HLfbHXLeUFn+VFYY2s394uHii37ASXO+02v/6H33P0RxcRFnnXU6I/JHsGXLVp58+hm2bUvM2UszZx7MhRecx+hRo6nuPEe6Ys1aS23P3Nxcnlj8GBddckWPX+Ap++3LRXO/z5gx5TQ0NvHSSy/z4UefxDXb7ONmccLx3+w6xbG4qIirrryMiRMnUlNby+OPP8WmrzYPOC9eGU85eQ4XX/SDXrsQnnz6Wd5/f1m/vw/xzAihf7aJ2I575wN45unH+cVtt7N9x84ey5aXlXH5ZRcxceJE2tvbeeXV1/nH0rdikivU64zD4eCiud9n5MiRrF23joWLFtPaGryB3vRpU/udNxRJUQ4iIhJflt+tJCIi8adyEBGRXlQOIiLSi8pBRER6UTmIiEgvKgcREelF5SAiIr2oHEREpBeVg4iI9PL/AQJOFN+5Nl26AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 460.8x403.2 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average runtime per epoch? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T13:27:42.339092Z",
     "start_time": "2020-01-19T13:27:42.335100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average runtime per epoch is 0.8272960317134858 seconds\n"
     ]
    }
   ],
   "source": [
    "avg_runtime = duration/EPOCHS\n",
    "print(f'The average runtime per epoch is {avg_runtime} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the number of parameters in the network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T12:50:31.294663Z",
     "start_time": "2020-01-21T12:50:31.287684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in the network is 9259\n"
     ]
    }
   ],
   "source": [
    "num_params = np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.all_variables()])\n",
    "print(f'The number of parameters in the network is {num_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a NN to solve the CIFAR-10 Dataset with the ‘le-net’ architecture shown in the presentation. Try to avoid code duplication as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:16:52.959162Z",
     "start_time": "2020-01-21T16:16:52.954176Z"
    }
   },
   "outputs": [],
   "source": [
    "std_X_train = std_X_train.reshape((len(std_X_train), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "std_X_test = std_X_test.reshape((len(std_X_test), 3, 32, 32)).transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:17:07.297479Z",
     "start_time": "2020-01-21T16:17:07.293455Z"
    }
   },
   "outputs": [],
   "source": [
    "ALPHA = 1e-2\n",
    "EPOCHS = 200\n",
    "HL_1_NEURONS = 3\n",
    "HL_2_NEURONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:17:07.689410Z",
     "start_time": "2020-01-21T16:17:07.682415Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, std_X_train.shape[1]])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:17:08.854243Z",
     "start_time": "2020-01-21T16:17:08.771465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weight and bias for the first convolutional layer\n",
    "WC1 = tf.Variable(tf.random_normal([5, 5, std_X_train.shape[1], 32], stddev=1), name='WC1')\n",
    "bC1 = tf.Variable(tf.random_normal([32]), name='bC1')\n",
    "\n",
    "# Weight and bias for the second convolutional layer\n",
    "WC2 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=1), name='WC2')\n",
    "bC2 = tf.Variable(tf.random_normal([64]), name='bC2')\n",
    "\n",
    "# Weight and bias for the first fully conected layer\n",
    "WFC1 = tf.Variable(tf.random_normal([64*5*5, HL_1_NEURONS], stddev=1), name='WFC1')\n",
    "bFC1 = tf.Variable(tf.random_normal([HL_1_NEURONS]), name='bFC1')\n",
    "\n",
    "# Weight and bias for the second fully conected layer\n",
    "WFC2 = tf.Variable(tf.random_normal([HL_1_NEURONS, HL_2_NEURONS], stddev=1), name='WFC2')\n",
    "bFC2 = tf.Variable(tf.random_normal([HL_2_NEURONS]), name='bFC2')\n",
    "\n",
    "# Weight and bias for the third fully conected layer\n",
    "WFC3 = tf.Variable(tf.random_normal([HL_2_NEURONS, 10], stddev=1), name='WFC3')\n",
    "bFC3 = tf.Variable(tf.random_normal([10]), name='bFC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:17:40.562716Z",
     "start_time": "2020-01-21T16:17:40.527808Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 2 for 'Conv2D_2' (op: 'Conv2D') with input shapes: [?,32], [5,5,32,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 2 for 'Conv2D_2' (op: 'Conv2D') with input shapes: [?,32], [5,5,32,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-51b341bb5cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute first convolutional layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mC_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWC1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mC_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbC1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mC_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mP_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1068\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1071\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    794\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3358\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3360\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3429\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3431\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1771\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1772\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1773\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1774\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1611\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1613\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 4 but is rank 2 for 'Conv2D_2' (op: 'Conv2D') with input shapes: [?,32], [5,5,32,32]."
     ]
    }
   ],
   "source": [
    "# Compute first convolutional layer\n",
    "C_1 = tf.nn.conv2d(X, WC1, strides=1, padding='SAME')\n",
    "C_1 = tf.nn.bias_add(C_1, bC1)\n",
    "C_1 = tf.nn.relu(C_1)\n",
    "P_1 = tf.nn.max_pool(C_1, ksize=3, strides=1, padding='same')\n",
    "\n",
    "# Compute second convolutional layer\n",
    "C_2 = tf.nn.conv2d(P_1, WC2, strides=1, padding='same')\n",
    "C_2 = tf.nn.bias_add(C_2, bC2)\n",
    "C_2 = tf.nn.relu(C_2)\n",
    "P_2 = tf.nn.max_pool(C_2, ksize=3, strides=1, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute first HL (use dropout in order to avoid overfitting)\n",
    "hl1 = tf.nn.relu(tf.add(tf.matmul(P2, WFC1), bFC1))\n",
    "hl1 = tf.nn.dropout(hl, 0.25)\n",
    "\n",
    "# Compute second HL (use dropout in order to avoid overfitting)\n",
    "hl2 = tf.nn.relu(tf.add(tf.matmul(hl1, WFC2), bFC2))\n",
    "hl2 = tf.nn.dropout(hl2, 0.25)\n",
    "\n",
    "# Compute prediction\n",
    "y_pred = tf.nn.softmax(tf.add(tf.matmul(hl2, WFC3), bFC3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate loss/cost and update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.add(tf.matmul(hl, W2), b2), labels=y_train_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.GradientDescentOptimizer(ALPHA)\n",
    "updates = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list = []\n",
    "batches = [std_X_1, std_X_2, std_X_3, std_X_4, std_X_5]\n",
    "with tf.Session() as sess:\n",
    "    for i in range\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train the model\n",
    "    values = {X: std_X_train,\n",
    "              y: y_train_one_hot}\n",
    "    start = time.time()\n",
    "    for e in range(EPOCHS):\n",
    "        cost_val, _ = sess.run([cost, updates], feed_dict=values)\n",
    "        cost_list.append(cost_val)\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    pred = sess.run([y_pred], feed_dict={X: std_X_test, y: y_test_one_hot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 architecture implementation using TensorFlow\n",
    "def LeNet_5(x):\n",
    " \n",
    " # Layer 1 : Convolutional Layer. Input = 32x32x1, Output = 28x28x1.\n",
    " conv1_w = tf.Variable(tf.truncated_normal(shape = [5,5,1,6],mean = 0, stddev = 0.1))\n",
    " conv1_b = tf.Variable(tf.zeros(6))\n",
    " conv1 = tf.nn.conv2d(x,conv1_w, strides = [1,1,1,1], padding = ‘VALID’) + conv1_b \n",
    " # TODO: Activation.\n",
    " conv1 = tf.nn.relu(conv1)\n",
    " \n",
    " # Pooling Layer. Input = 28x28x1. Output = 14x14x6.\n",
    " pool_1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = ‘VALID’)\n",
    " \n",
    " \n",
    " # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    " conv2_w = tf.Variable(tf.truncated_normal(shape = [5,5,6,16], mean = 0, stddev = 0.1))\n",
    " conv2_b = tf.Variable(tf.zeros(16))\n",
    " conv2 = tf.nn.conv2d(pool_1, conv2_w, strides = [1,1,1,1], padding = ‘VALID’) + conv2_b\n",
    " # TODO: Activation.\n",
    " conv2 = tf.nn.relu(conv2)\n",
    "# TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    " pool_2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = ‘VALID’)\n",
    " \n",
    " \n",
    " # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    " fc1 = flatten(pool_2)\n",
    " \n",
    " \n",
    " # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    " fc1_w = tf.Variable(tf.truncated_normal(shape = (400,120), mean = 0, stddev = 0.1))\n",
    " fc1_b = tf.Variable(tf.zeros(120))\n",
    " fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
    " \n",
    " # TODO: Activation.\n",
    " fc1 = tf.nn.relu(fc1)\n",
    " \n",
    " # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    " fc2_w = tf.Variable(tf.truncated_normal(shape = (120,84), mean = 0, stddev = 0.1))\n",
    " fc2_b = tf.Variable(tf.zeros(84))\n",
    " fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
    " # TODO: Activation.\n",
    " fc2 = tf.nn.relu(fc2)\n",
    " \n",
    " # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    " fc3_w = tf.Variable(tf.truncated_normal(shape = (84,10), mean = 0 , stddev = 0.1))\n",
    " fc3_b = tf.Variable(tf.zeros(10))\n",
    " logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
    " return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
